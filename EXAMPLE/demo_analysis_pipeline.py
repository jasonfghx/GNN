#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç™»é©çƒ­NS5æŠ‘åˆ¶å‰‚é¢„æµ‹ - ç®€åŒ–æ¼”ç¤ºæµæ°´çº¿
Dengue NS5 Inhibitor Prediction - Simplified Demo Pipeline

æœ¬è„šæœ¬æ¼”ç¤ºæ ¸å¿ƒåŠŸèƒ½ï¼Œé¿å…RDKitå…¼å®¹æ€§é—®é¢˜
"""

import os
import sys
import torch
import numpy as np
import pandas as pd
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
try:
    from dengue_ns5_inhibitor_prediction import (
        DengueNS5InhibitorPredictor, MolecularGraphDataset
    )
    from top_hit_recommendation_system import TopHitRecommendationSystem
    CORE_MODULES_AVAILABLE = True
except ImportError as e:
    print(f"æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    CORE_MODULES_AVAILABLE = False

class SimplifiedAnalysisPipeline:
    """ç®€åŒ–çš„åˆ†ææµæ°´çº¿"""
    
    def __init__(self, output_dir="demo_output", device=None):
        self.output_dir = output_dir
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.protein_data = None
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        for subdir in ['models', 'evaluations', 'recommendations', 'reports']:
            os.makedirs(os.path.join(output_dir, subdir), exist_ok=True)
    
    def setup_environment(self):
        """è®¾ç½®åˆ†æç¯å¢ƒ"""
        print("\n=== è®¾ç½®åˆ†æç¯å¢ƒ ===")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        if torch.cuda.is_available():
            print(f"GPU: {torch.cuda.get_device_name()}")
        print("ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    def load_or_create_model(self, model_path=None):
        """åŠ è½½æˆ–åˆ›å»ºæ¨¡å‹"""
        print("\n=== æ¨¡å‹åˆå§‹åŒ– ===")
        
        try:
            # åˆ›å»ºæ¨¡æ‹Ÿè›‹ç™½è´¨æ•°æ®
            self.protein_data = self._create_mock_protein_data()
            print("ä½¿ç”¨æ¨¡æ‹Ÿè›‹ç™½è´¨æ•°æ®")
            
            if model_path and os.path.exists(model_path):
                # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
                print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {model_path}")
                self.model = DengueNS5InhibitorPredictor(fusion_strategy='joint_graph')
                checkpoint = torch.load(model_path, map_location=self.device)
                self.model.load_state_dict(checkpoint)
                self.model.to(self.device)
                print("æ¨¡å‹åŠ è½½æˆåŠŸ")
            else:
                # åˆ›å»ºæ–°æ¨¡å‹
                print("åˆ›å»ºæ–°æ¨¡å‹")
                self.model = DengueNS5InhibitorPredictor(
                    fusion_strategy='joint_graph'
                ).to(self.device)
                print("æ¨¡å‹åˆ›å»ºæˆåŠŸ")
            
            print(f"æ¨¡å‹å·²åŠ è½½åˆ°: {self.device}")
            return True
            
        except Exception as e:
            print(f"æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def _create_mock_protein_data(self):
        """åˆ›å»ºæ¨¡æ‹Ÿè›‹ç™½è´¨æ•°æ®"""
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è›‹ç™½è´¨å›¾æ•°æ®
        num_residues = 100
        protein_features = torch.randn(num_residues, 20)  # 20ç»´æ°¨åŸºé…¸ç‰¹å¾
        
        # åˆ›å»ºç®€å•çš„è¾¹è¿æ¥ï¼ˆç›¸é‚»æ®‹åŸºè¿æ¥ï¼‰
        edge_indices = []
        for i in range(num_residues - 1):
            edge_indices.extend([[i, i+1], [i+1, i]])
        
        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
        edge_attr = torch.ones(edge_index.size(1), 1)  # ç®€å•çš„è¾¹ç‰¹å¾
        
        from torch_geometric.data import Data
        protein_data = Data(
            x=protein_features,
            edge_index=edge_index,
            edge_attr=edge_attr
        )
        
        return protein_data.to(self.device)
    
    def prepare_demo_dataset(self):
        """å‡†å¤‡æ¼”ç¤ºæ•°æ®é›†"""
        print("\n=== æ•°æ®é›†å‡†å¤‡ ===")
        
        # åˆ›å»ºç¤ºä¾‹SMILESæ•°æ®
        demo_smiles = [
            'CCO',  # ä¹™é†‡
            'CC(=O)O',  # ä¹™é…¸
            'c1ccccc1',  # è‹¯
            'CCN(CC)CC',  # ä¸‰ä¹™èƒº
            'CC(C)O',  # å¼‚ä¸™é†‡
            'CCCCO',  # ä¸é†‡
            'c1ccc(cc1)O',  # è‹¯é…š
            'CC(=O)N',  # ä¹™é…°èƒº
            'CCCC',  # ä¸çƒ·
            'c1ccc2ccccc2c1',  # è˜
            'CC(C)(C)O',  # å”ä¸é†‡
            'CCc1ccccc1',  # ä¹™è‹¯
            'CC(=O)OC',  # ä¹™é…¸ç”²é…¯
            'c1ccc(cc1)N',  # è‹¯èƒº
            'CCOCC',  # äºŒä¹™é†š
            'CC(C)C',  # å¼‚ä¸çƒ·
            'c1ccc(cc1)C',  # ç”²è‹¯
            'CC(=O)CC',  # ä¸™é…®
            'CCCCC',  # æˆŠçƒ·
            'c1ccc(cc1)Cl',  # æ°¯è‹¯
        ]
        
        # åˆ›å»ºéšæœºæ ‡ç­¾ï¼ˆæ´»æ€§/éæ´»æ€§ï¼‰
        np.random.seed(42)
        demo_labels = np.random.randint(0, 2, len(demo_smiles))
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = MolecularGraphDataset(
            smiles_list=demo_smiles,
            labels=demo_labels.tolist()
        )
        
        print(f"ä½¿ç”¨æ¼”ç¤ºæ•°æ®é›†: {len(demo_smiles)} ä¸ªåŒ–åˆç‰©")
        print(f"æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»åŒ–åˆç‰©æ•°: {len(demo_smiles)}")
        print(f"  æ´»æ€§åŒ–åˆç‰©æ•°: {sum(demo_labels)}")
        print(f"  éæ´»æ€§åŒ–åˆç‰©æ•°: {len(demo_labels) - sum(demo_labels)}")
        
        return dataset, demo_smiles, demo_labels
    
    def basic_model_evaluation(self, dataset):
        """åŸºæœ¬æ¨¡å‹è¯„ä¼°"""
        print("\n=== åŸºæœ¬æ¨¡å‹è¯„ä¼° ===")
        
        try:
            # ç®€å•çš„å‰å‘ä¼ æ’­æµ‹è¯•
            self.model.eval()
            
            predictions = []
            labels = []
            
            with torch.no_grad():
                for i in range(min(10, len(dataset))):
                    mol_data, label = dataset[i]
                    mol_data = mol_data.to(self.device)
                    
                    # åˆ›å»ºæ‰¹æ¬¡
                    from torch_geometric.data import Batch
                    batch_mol = Batch.from_data_list([mol_data]).to(self.device)
                    
                    # é¢„æµ‹
                    output = self.model(batch_mol, self.protein_data)
                    pred = torch.sigmoid(output).cpu().numpy()[0]
                    
                    predictions.append(pred)
                    labels.append(label)
            
            # è®¡ç®—ç®€å•æŒ‡æ ‡
            predictions = np.array(predictions)
            labels = np.array(labels)
            binary_preds = (predictions > 0.5).astype(int)
            
            accuracy = np.mean(binary_preds == labels)
            
            print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(predictions)}")
            print(f"å‡†ç¡®ç‡: {accuracy:.3f}")
            print(f"å¹³å‡é¢„æµ‹æ¦‚ç‡: {np.mean(predictions):.3f}")
            
            return {
                'accuracy': accuracy,
                'predictions': predictions,
                'labels': labels
            }
            
        except Exception as e:
            print(f"æ¨¡å‹è¯„ä¼°å¤±è´¥: {e}")
            return None
    
    def demo_top_hit_recommendation(self, smiles_list, labels):
        """æ¼”ç¤ºTop-HitåŒ–åˆç‰©æ¨è"""
        print("\n=== Top-HitåŒ–åˆç‰©æ¨è ===")
        
        try:
            # åˆ›å»ºæ¨èç³»ç»Ÿ
            recommender = TopHitRecommendationSystem(
                model=self.model,
                protein_data=self.protein_data,
                device=self.device
            )
            
            # è·å–æ¨èç»“æœ
            recommendations = recommender.get_top_hits(
                smiles_list=smiles_list,
                top_n=5
            )
            
            print("Top-5 æ¨èåŒ–åˆç‰©:")
            for i, rec in enumerate(recommendations[:5], 1):
                print(f"{i}. SMILES: {rec['smiles']}")
                print(f"   é¢„æµ‹æ´»æ€§: {rec['predicted_activity']:.3f}")
                print(f"   ç»¼åˆè¯„åˆ†: {rec['composite_score']:.3f}")
                print()
            
            # ä¿å­˜ç»“æœ
            output_file = os.path.join(self.output_dir, 'recommendations', 'top_hits_demo.csv')
            recommender.export_recommendations(recommendations, output_file)
            print(f"æ¨èç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            
            return recommendations
            
        except Exception as e:
            print(f"Top-Hitæ¨èå¤±è´¥: {e}")
            return None
    
    def generate_demo_report(self, eval_results, recommendations):
        """ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š"""
        print("\n=== ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š ===")
        
        try:
            report_file = os.path.join(self.output_dir, 'reports', 'demo_analysis_report.md')
            
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write("# ç™»é©çƒ­NS5æŠ‘åˆ¶å‰‚é¢„æµ‹ - æ¼”ç¤ºåˆ†ææŠ¥å‘Š\n\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                
                f.write("## æ¨¡å‹ä¿¡æ¯\n")
                f.write(f"- èåˆç­–ç•¥: Joint Graph\n")
                f.write(f"- è®¾å¤‡: {self.device}\n")
                f.write(f"- è›‹ç™½è´¨æ•°æ®: æ¨¡æ‹Ÿæ•°æ® (100ä¸ªæ®‹åŸº)\n\n")
                
                if eval_results:
                    f.write("## æ¨¡å‹è¯„ä¼°ç»“æœ\n")
                    f.write(f"- æµ‹è¯•å‡†ç¡®ç‡: {eval_results['accuracy']:.3f}\n")
                    f.write(f"- å¹³å‡é¢„æµ‹æ¦‚ç‡: {np.mean(eval_results['predictions']):.3f}\n\n")
                
                if recommendations:
                    f.write("## Top-HitåŒ–åˆç‰©æ¨è\n")
                    f.write("| æ’å | SMILES | é¢„æµ‹æ´»æ€§ | ç»¼åˆè¯„åˆ† |\n")
                    f.write("|------|--------|----------|----------|\n")
                    for i, rec in enumerate(recommendations[:5], 1):
                        f.write(f"| {i} | {rec['smiles']} | {rec['predicted_activity']:.3f} | {rec['composite_score']:.3f} |\n")
                    f.write("\n")
                
                f.write("## åŠŸèƒ½æ¨¡å—çŠ¶æ€\n")
                f.write("- âœ… æ ¸å¿ƒæ¨¡å‹é¢„æµ‹\n")
                f.write("- âœ… Top-HitåŒ–åˆç‰©æ¨è\n")
                f.write("- âœ… åŸºæœ¬æ¨¡å‹è¯„ä¼°\n")
                f.write("- âš ï¸ é«˜çº§å¯è§†åŒ– (RDKitå…¼å®¹æ€§é—®é¢˜)\n")
                f.write("- âš ï¸ SHAPåˆ†æ (éœ€è¦å®‰è£…SHAPåº“)\n")
                
                f.write("\n## æ³¨æ„äº‹é¡¹\n")
                f.write("- æœ¬æ¼”ç¤ºä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®å’Œç®€åŒ–æ¨¡å‹\n")
                f.write("- å®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®çš„è›‹ç™½è´¨ç»“æ„æ•°æ®\n")
                f.write("- å»ºè®®è§£å†³RDKitå’ŒNumPyå…¼å®¹æ€§é—®é¢˜ä»¥è·å¾—å®Œæ•´åŠŸèƒ½\n")
            
            print(f"æ¼”ç¤ºæŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
            return report_file
            
        except Exception as e:
            print(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return None
    
    def run_complete_demo(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("\n" + "="*60)
        print("    ç™»é©çƒ­NS5æŠ‘åˆ¶å‰‚é¢„æµ‹ - ç®€åŒ–æ¼”ç¤ºæµæ°´çº¿")
        print("    Dengue NS5 Inhibitor Prediction - Simplified Demo")
        print("="*60)
        
        try:
            # 1. ç¯å¢ƒè®¾ç½®
            self.setup_environment()
            
            # 2. æ¨¡å‹åˆå§‹åŒ–
            if not self.load_or_create_model():
                print("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
                return False
            
            # 3. æ•°æ®å‡†å¤‡
            dataset, smiles_list, labels = self.prepare_demo_dataset()
            
            # 4. åŸºæœ¬è¯„ä¼°
            print("\n1. æ‰§è¡ŒåŸºæœ¬æ¨¡å‹è¯„ä¼°...")
            eval_results = self.basic_model_evaluation(dataset)
            
            # 5. Top-Hitæ¨è
            print("\n2. æ‰§è¡ŒTop-HitåŒ–åˆç‰©æ¨è...")
            recommendations = self.demo_top_hit_recommendation(smiles_list, labels)
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            print("\n3. ç”Ÿæˆæ¼”ç¤ºæŠ¥å‘Š...")
            report_file = self.generate_demo_report(eval_results, recommendations)
            
            print("\n" + "="*60)
            print("âœ… æ¼”ç¤ºå®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
            if report_file:
                print(f"ğŸ“„ æ¼”ç¤ºæŠ¥å‘Š: {report_file}")
            print("="*60)
            
            return True
            
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    if not CORE_MODULES_AVAILABLE:
        print("é”™è¯¯: æ ¸å¿ƒæ¨¡å—æ— æ³•å¯¼å…¥ï¼Œè¯·æ£€æŸ¥ä¾èµ–é¡¹")
        return False
    
    # åˆ›å»ºæ¼”ç¤ºæµæ°´çº¿
    demo_pipeline = SimplifiedAnalysisPipeline(
        output_dir="demo_output",
        device="cuda" if torch.cuda.is_available() else "cpu"
    )
    
    # è¿è¡Œæ¼”ç¤º
    success = demo_pipeline.run_complete_demo()
    
    if success:
        print("\nğŸ‰ æ¼”ç¤ºæˆåŠŸå®Œæˆ!")
        print("\nğŸ“‹ åŠŸèƒ½æ€»ç»“:")
        print("- âœ… æ¨¡å‹åŠ è½½å’Œåˆå§‹åŒ–")
        print("- âœ… åˆ†å­å›¾æ•°æ®å¤„ç†")
        print("- âœ… åŸºæœ¬æ¨¡å‹è¯„ä¼°")
        print("- âœ… Top-HitåŒ–åˆç‰©æ¨è")
        print("- âœ… ç»“æœå¯¼å‡ºå’ŒæŠ¥å‘Šç”Ÿæˆ")
        print("\nğŸ’¡ æç¤º: æŸ¥çœ‹ demo_output/ ç›®å½•è·å–è¯¦ç»†ç»“æœ")
    else:
        print("\nâŒ æ¼”ç¤ºæ‰§è¡Œå¤±è´¥")
    
    return success

if __name__ == "__main__":
    main()