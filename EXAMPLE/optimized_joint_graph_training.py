import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch_geometric.data import Data, Batch
from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool, global_add_pool
from rdkit import Chem
from rdkit.Chem import Descriptors, rdMolDescriptors
from Bio.PDB import PDBParser
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_curve, auc, confusion_matrix, f1_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class EnhancedMolecularGraphDataset(Dataset):
    """å¢å¼ºçš„åˆ†å­å›¾æ•°æ®é›†"""
    def __init__(self, smiles_list, labels, protein_features=None):
        self.smiles_list = smiles_list
        self.labels = labels
        self.protein_features = protein_features
        
    def smiles_to_graph(self, smiles):
        """å°†SMILESè½¬æ¢ä¸ºå¢å¼ºçš„å›¾æ•°æ®"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            if mol is None:
                return self.create_empty_graph()
            
            # å¢å¼ºçš„åŸå­ç‰¹å¾
            atom_features = []
            for atom in mol.GetAtoms():
                features = [
                    atom.GetAtomicNum(),
                    atom.GetDegree(),
                    atom.GetFormalCharge(),
                    int(atom.GetHybridization()),
                    int(atom.GetIsAromatic()),
                    atom.GetTotalNumHs(),
                    atom.GetMass(),
                    int(atom.IsInRing()),
                    atom.GetTotalValence(),
                    int(atom.GetChiralTag())
                ]
                atom_features.append(features)
            
            # è¾¹ä¿¡æ¯å’Œè¾¹ç‰¹å¾
            edge_indices = []
            edge_features = []
            for bond in mol.GetBonds():
                i = bond.GetBeginAtomIdx()
                j = bond.GetEndAtomIdx()
                
                bond_features = [
                    int(bond.GetBondType()),
                    int(bond.GetIsAromatic()),
                    int(bond.IsInRing()),
                    int(bond.GetStereo())
                ]
                
                edge_indices.extend([[i, j], [j, i]])
                edge_features.extend([bond_features, bond_features])
            
            # åˆ†å­æè¿°ç¬¦
            mol_descriptors = [
                Descriptors.MolWt(mol),
                Descriptors.MolLogP(mol),
                Descriptors.NumHDonors(mol),
                Descriptors.NumHAcceptors(mol),
                Descriptors.TPSA(mol),
                Descriptors.NumRotatableBonds(mol),
                Descriptors.NumAromaticRings(mol),
                Descriptors.FractionCsp3(mol)
            ]
            
            if len(edge_indices) == 0:
                edge_indices = [[0, 0]]
                edge_features = [[0, 0, 0, 0]]
            
            x = torch.tensor(atom_features, dtype=torch.float)
            edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
            edge_attr = torch.tensor(edge_features, dtype=torch.float)
            mol_desc = torch.tensor(mol_descriptors, dtype=torch.float)
            
            return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, mol_descriptors=mol_desc)
            
        except Exception as e:
            return self.create_empty_graph()
    
    def create_empty_graph(self):
        """åˆ›å»ºç©ºå›¾"""
        x = torch.zeros((1, 10), dtype=torch.float)
        edge_index = torch.tensor([[0], [0]], dtype=torch.long)
        edge_attr = torch.zeros((1, 4), dtype=torch.float)
        mol_desc = torch.zeros(8, dtype=torch.float)
        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, mol_descriptors=mol_desc)
    
    def __len__(self):
        return len(self.smiles_list)
    
    def __getitem__(self, idx):
        smiles = self.smiles_list[idx]
        label = self.labels[idx]
        graph = self.smiles_to_graph(smiles)
        return graph, label

class EnhancedProteinProcessor:
    """å¢å¼ºçš„è›‹ç™½è´¨å¤„ç†å™¨"""
    def __init__(self, pdb_file):
        self.pdb_file = pdb_file
        self.protein_graph = self.create_protein_graph()
    
    def create_protein_graph(self):
        """åˆ›å»ºå¢å¼ºçš„è›‹ç™½è´¨å›¾"""
        try:
            parser = PDBParser(QUIET=True)
            structure = parser.get_structure('protein', self.pdb_file)
            
            # æå–æ°¨åŸºé…¸æ®‹åŸºç‰¹å¾
            residue_features = []
            residue_coords = []
            
            for residue in structure.get_residues():
                if residue.get_id()[0] == ' ':  # åªå¤„ç†æ ‡å‡†æ®‹åŸº
                    # æ®‹åŸºç±»å‹ç¼–ç 
                    aa_dict = {'ALA': 1, 'ARG': 2, 'ASN': 3, 'ASP': 4, 'CYS': 5,
                              'GLN': 6, 'GLU': 7, 'GLY': 8, 'HIS': 9, 'ILE': 10,
                              'LEU': 11, 'LYS': 12, 'MET': 13, 'PHE': 14, 'PRO': 15,
                              'SER': 16, 'THR': 17, 'TRP': 18, 'TYR': 19, 'VAL': 20}
                    
                    resname = residue.get_resname()
                    aa_type = aa_dict.get(resname, 0)
                    
                    # è®¡ç®—æ®‹åŸºä¸­å¿ƒåæ ‡
                    coords = []
                    for atom in residue.get_atoms():
                        coords.append(atom.get_coord())
                    
                    if coords:
                        center = np.mean(coords, axis=0)
                        residue_coords.append(center)
                        
                        # æ®‹åŸºç‰¹å¾ï¼šç±»å‹ã€ç–æ°´æ€§ã€ç”µè·ç­‰
                        hydrophobic = 1 if resname in ['ALA', 'VAL', 'LEU', 'ILE', 'PHE', 'TRP', 'MET'] else 0
                        charged = 1 if resname in ['ARG', 'LYS', 'ASP', 'GLU'] else 0
                        polar = 1 if resname in ['SER', 'THR', 'ASN', 'GLN', 'TYR'] else 0
                        
                        features = [aa_type, hydrophobic, charged, polar, len(coords)]
                        residue_features.append(features)
            
            if len(residue_features) == 0:
                # åˆ›å»ºé»˜è®¤è›‹ç™½è´¨å›¾
                x = torch.zeros((1, 5), dtype=torch.float)
                edge_index = torch.tensor([[0], [0]], dtype=torch.long)
                return Data(x=x, edge_index=edge_index)
            
            # æ„å»ºè›‹ç™½è´¨å›¾çš„è¾¹ï¼ˆåŸºäºè·ç¦»ï¼‰
            residue_coords = np.array(residue_coords)
            edge_indices = []
            
            for i in range(len(residue_coords)):
                for j in range(i+1, len(residue_coords)):
                    dist = np.linalg.norm(residue_coords[i] - residue_coords[j])
                    if dist < 10.0:  # 10åŸƒè·ç¦»é˜ˆå€¼
                        edge_indices.extend([[i, j], [j, i]])
            
            if len(edge_indices) == 0:
                edge_indices = [[0, 0]]
            
            x = torch.tensor(residue_features, dtype=torch.float)
            edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()
            
            return Data(x=x, edge_index=edge_index)
            
        except Exception as e:
            print(f"è›‹ç™½è´¨å¤„ç†é”™è¯¯: {e}")
            x = torch.zeros((1, 5), dtype=torch.float)
            edge_index = torch.tensor([[0], [0]], dtype=torch.long)
            return Data(x=x, edge_index=edge_index)

class OptimizedJointGraphPredictor(nn.Module):
    """ä¼˜åŒ–çš„è”åˆå›¾é¢„æµ‹å™¨"""
    def __init__(self, mol_input_dim=10, protein_input_dim=5, hidden_dim=256, dropout=0.3):
        super().__init__()
        
        # åˆ†å­å›¾ç¼–ç å™¨ï¼ˆå¤šå±‚GCN + GATï¼‰
        self.mol_gcn1 = GCNConv(mol_input_dim, hidden_dim)
        self.mol_gcn2 = GCNConv(hidden_dim, hidden_dim)
        self.mol_gat1 = GATConv(hidden_dim, hidden_dim//4, heads=4, dropout=dropout)
        self.mol_gat2 = GATConv(hidden_dim, hidden_dim//4, heads=4, dropout=dropout)
        
        # è›‹ç™½è´¨å›¾ç¼–ç å™¨
        self.protein_gcn1 = GCNConv(protein_input_dim, hidden_dim)
        self.protein_gcn2 = GCNConv(hidden_dim, hidden_dim)
        self.protein_gat = GATConv(hidden_dim, hidden_dim//4, heads=4, dropout=dropout)
        
        # åˆ†å­æè¿°ç¬¦å¤„ç† - ä¿®æ­£è¾“å…¥ç»´åº¦
        self.mol_desc_fc = nn.Sequential(
            nn.Linear(512, hidden_dim//2),  # ä¿®æ­£ä¸ºå®é™…è¾“å…¥ç»´åº¦
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim//2, hidden_dim//2)
        )
        
        # äº¤å‰æ³¨æ„åŠ›æœºåˆ¶
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=hidden_dim, num_heads=8, dropout=dropout, batch_first=True
        )
        
        # è”åˆå›¾å­¦ä¹ 
        self.joint_transform = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout)
        )
        
        # å¤šå°ºåº¦æ± åŒ–
        self.pool_layers = nn.ModuleList([
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.Linear(hidden_dim, hidden_dim//2)
        ])
        
        # æœ€ç»ˆé¢„æµ‹å±‚
        self.predictor = nn.Sequential(
            nn.Linear(hidden_dim + hidden_dim//2 + hidden_dim//2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, hidden_dim//2),
            nn.ReLU(),
            nn.Dropout(dropout//2),
            nn.Linear(hidden_dim//2, 1),
            nn.Sigmoid()
        )
        
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, mol_batch, protein_data):
        # åˆ†å­å›¾ç¼–ç 
        mol_x = F.relu(self.mol_gcn1(mol_batch.x, mol_batch.edge_index))
        mol_x = self.dropout(mol_x)
        mol_x = F.relu(self.mol_gcn2(mol_x, mol_batch.edge_index))
        mol_x = self.dropout(mol_x)
        
        mol_x_gat = F.relu(self.mol_gat1(mol_x, mol_batch.edge_index))
        mol_x_gat = self.dropout(mol_x_gat)
        mol_x_gat = F.relu(self.mol_gat2(mol_x_gat, mol_batch.edge_index))
        
        # å¤šå°ºåº¦æ± åŒ–
        mol_mean = global_mean_pool(mol_x_gat, mol_batch.batch)
        mol_max = global_max_pool(mol_x_gat, mol_batch.batch)
        mol_add = global_add_pool(mol_x_gat, mol_batch.batch)
        
        # å¤„ç†åˆ†å­æè¿°ç¬¦
        # ç¡®ä¿åˆ†å­æè¿°ç¬¦çš„å½¢çŠ¶æ­£ç¡®å¹¶åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        if mol_batch.mol_descriptors.dim() == 1:
            mol_desc_input = mol_batch.mol_descriptors.unsqueeze(0).to(mol_mean.device)
        else:
            mol_desc_input = mol_batch.mol_descriptors.to(mol_mean.device)
        
        # å¦‚æœæ‰¹æ¬¡ä¸­æœ‰å¤šä¸ªåˆ†å­ï¼Œéœ€è¦æ­£ç¡®å¤„ç†ç»´åº¦
        if mol_desc_input.size(0) != mol_mean.size(0):
            # é‡æ–°ç»„ç»‡åˆ†å­æè¿°ç¬¦ä»¥åŒ¹é…æ‰¹æ¬¡å¤§å°
            batch_size = mol_mean.size(0)
            mol_desc_input = mol_desc_input.view(batch_size, -1)
        
        mol_desc = self.mol_desc_fc(mol_desc_input)
        
        # è›‹ç™½è´¨å›¾ç¼–ç 
        protein_x = F.relu(self.protein_gcn1(protein_data.x, protein_data.edge_index))
        protein_x = self.dropout(protein_x)
        protein_x = F.relu(self.protein_gcn2(protein_x, protein_data.edge_index))
        protein_x = F.relu(self.protein_gat(protein_x, protein_data.edge_index))
        
        protein_global = global_mean_pool(protein_x, torch.zeros(protein_x.size(0), dtype=torch.long, device=protein_x.device))
        protein_global = protein_global.expand(mol_mean.size(0), -1)
        
        # äº¤å‰æ³¨æ„åŠ›
        mol_attended, _ = self.cross_attention(
            mol_mean.unsqueeze(1), 
            protein_global.unsqueeze(1), 
            protein_global.unsqueeze(1)
        )
        mol_attended = mol_attended.squeeze(1)
        
        # è”åˆç‰¹å¾
        joint_features = torch.cat([mol_attended, protein_global], dim=1)
        joint_features = self.joint_transform(joint_features)
        
        # å¤šå°ºåº¦ç‰¹å¾èåˆ
        pooled_mean = self.pool_layers[0](mol_mean)
        pooled_max = self.pool_layers[1](mol_max)
        
        # æœ€ç»ˆç‰¹å¾ç»„åˆ - ç¡®ä¿æ‰€æœ‰å¼ é‡åœ¨åŒä¸€è®¾å¤‡ä¸Š
        device = joint_features.device
        pooled_mean = pooled_mean.to(device)
        mol_desc = mol_desc.to(device)
        final_features = torch.cat([joint_features, pooled_mean, mol_desc], dim=1)
        
        # é¢„æµ‹
        output = self.predictor(final_features)
        return output

def load_enhanced_data():
    """åŠ è½½å¹¶å¢å¼ºæ•°æ®"""
    try:
        # åŠ è½½æ´»æ€§åŒ–åˆç‰©æ•°æ® - ä½¿ç”¨åˆ†å·ä½œä¸ºåˆ†éš”ç¬¦ï¼Œå¤„ç†å¼•å·
        active_df = pd.read_csv('DENV inhibitors RdRp_ç™»é©ç†±ç—…æ¯’æŠ‘åˆ¶ç‰©_3739(2).csv', sep=';', quotechar='"', on_bad_lines='skip')
        active_smiles = active_df['Smiles'].dropna().tolist()
        
        # åŠ è½½éæ´»æ€§åŒ–åˆç‰©
        inactive_df = pd.read_csv('inactive compounds_ç„¡æ´»æ€§æŠ‘åˆ¶ç‰©(1).csv', sep=';', quotechar='"', on_bad_lines='skip')
        inactive_smiles = inactive_df['Smiles'].dropna().tolist()
        
        # éªŒè¯SMILES
        valid_active_smiles = []
        for smiles in active_smiles:
            mol = Chem.MolFromSmiles(smiles)
            if mol is not None:
                valid_active_smiles.append(smiles)
        
        valid_inactive_smiles = []
        for smiles in inactive_smiles:
            mol = Chem.MolFromSmiles(smiles)
            if mol is not None:
                valid_inactive_smiles.append(smiles)
        
        # ä½¿ç”¨æ›´å¤šæ•°æ®ï¼ˆå¢åŠ åˆ°2000ä¸ªæ´»æ€§ï¼Œ1000ä¸ªéæ´»æ€§ï¼‰
        active_sample_size = min(2000, len(valid_active_smiles))
        inactive_sample_size = min(1000, len(valid_inactive_smiles))
        
        np.random.seed(42)
        sampled_active = np.random.choice(valid_active_smiles, active_sample_size, replace=False)
        sampled_inactive = np.random.choice(valid_inactive_smiles, inactive_sample_size, replace=False)
        
        all_smiles = list(sampled_active) + list(sampled_inactive)
        all_labels = [1] * len(sampled_active) + [0] * len(sampled_inactive)
        
        print(f"æ´»æ€§åŒ–åˆç‰©æ•°é‡: {len(sampled_active)}")
        print(f"éæ´»æ€§åŒ–åˆç‰©æ•°é‡: {len(sampled_inactive)}")
        print(f"æ€»åŒ–åˆç‰©æ•°é‡: {len(all_smiles)}")
        
        return all_smiles, all_labels
        
    except Exception as e:
        print(f"æ•°æ®åŠ è½½é”™è¯¯: {e}")
        return None, None

def train_optimized_model():
    """è®­ç»ƒä¼˜åŒ–çš„æ¨¡å‹"""
    print("=== ä¼˜åŒ–Joint Graphç­–ç•¥è®­ç»ƒ ===")
    
    # åŠ è½½æ•°æ®
    smiles_list, labels = load_enhanced_data()
    if smiles_list is None:
        return None
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = EnhancedMolecularGraphDataset(smiles_list, labels)
    
    # 5æŠ˜äº¤å‰éªŒè¯
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
    fold_results = []
    
    for fold, (train_val_idx, test_idx) in enumerate(skf.split(smiles_list, labels)):
        print(f"\n=== ç¬¬ {fold+1} æŠ˜è®­ç»ƒ ===")
        
        # è¿›ä¸€æ­¥åˆ†å‰²è®­ç»ƒå’ŒéªŒè¯é›†
        train_labels = [labels[i] for i in train_val_idx]
        train_idx, val_idx = train_test_split(
            train_val_idx, test_size=0.2, random_state=42, stratify=train_labels
        )
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        def collate_fn(batch):
            mol_graphs, labels = zip(*batch)
            return Batch.from_data_list(mol_graphs), torch.tensor(labels, dtype=torch.float)
        
        train_dataset = torch.utils.data.Subset(dataset, train_idx)
        val_dataset = torch.utils.data.Subset(dataset, val_idx)
        test_dataset = torch.utils.data.Subset(dataset, test_idx)
        
        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)
        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)
        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)
        
        # åˆ›å»ºæ¨¡å‹
        model = OptimizedJointGraphPredictor(hidden_dim=512, dropout=0.2)
        protein_processor = EnhancedProteinProcessor('Dengue virus 3åºåˆ—.pdb')
        protein_data = protein_processor.protein_graph
        
        # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=10, verbose=True
        )
        criterion = nn.BCELoss()
        
        # è®­ç»ƒå¾ªç¯
        best_val_auc = 0
        patience_counter = 0
        epochs = 100
        
        for epoch in range(epochs):
            # è®­ç»ƒ
            model.train()
            total_loss = 0
            for batch_mol, batch_labels in train_loader:
                optimizer.zero_grad()
                outputs = model(batch_mol, protein_data)
                loss = criterion(outputs.squeeze(), batch_labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                total_loss += loss.item()
            
            # éªŒè¯
            model.eval()
            val_preds = []
            val_true = []
            
            with torch.no_grad():
                for batch_mol, batch_labels in val_loader:
                    outputs = model(batch_mol, protein_data)
                    val_preds.extend(outputs.squeeze().tolist())
                    val_true.extend(batch_labels.tolist())
            
            val_auc = roc_auc_score(val_true, val_preds)
            scheduler.step(val_auc)
            
            if val_auc > best_val_auc:
                best_val_auc = val_auc
                patience_counter = 0
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                torch.save(model.state_dict(), f'best_optimized_model_fold_{fold}.pth')
            else:
                patience_counter += 1
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}: Loss: {total_loss/len(train_loader):.4f}, Val AUC: {val_auc:.4f}")
            
            if patience_counter >= 20:  # æ—©åœ
                print(f"æ—©åœäºç¬¬ {epoch} è½®")
                break
        
        # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
        model.load_state_dict(torch.load(f'best_optimized_model_fold_{fold}.pth'))
        model.eval()
        
        test_preds = []
        test_true = []
        
        with torch.no_grad():
            for batch_mol, batch_labels in test_loader:
                outputs = model(batch_mol, protein_data)
                test_preds.extend(outputs.squeeze().tolist())
                test_true.extend(batch_labels.tolist())
        
        test_auc = roc_auc_score(test_true, test_preds)
        test_preds_binary = [1 if p > 0.5 else 0 for p in test_preds]
        test_acc = accuracy_score(test_true, test_preds_binary)
        test_f1 = f1_score(test_true, test_preds_binary)
        
        fold_result = {
            'fold': fold + 1,
            'test_auc': test_auc,
            'test_acc': test_acc,
            'test_f1': test_f1
        }
        fold_results.append(fold_result)
        
        print(f"ç¬¬ {fold+1} æŠ˜ç»“æœ: AUC={test_auc:.4f}, Acc={test_acc:.4f}, F1={test_f1:.4f}")
    
    # è®¡ç®—å¹³å‡ç»“æœ
    avg_auc = np.mean([r['test_auc'] for r in fold_results])
    avg_acc = np.mean([r['test_acc'] for r in fold_results])
    avg_f1 = np.mean([r['test_f1'] for r in fold_results])
    std_auc = np.std([r['test_auc'] for r in fold_results])
    
    print(f"\n=== 5æŠ˜äº¤å‰éªŒè¯æœ€ç»ˆç»“æœ ===")
    print(f"å¹³å‡AUC: {avg_auc:.4f} Â± {std_auc:.4f}")
    print(f"å¹³å‡å‡†ç¡®ç‡: {avg_acc:.4f}")
    print(f"å¹³å‡F1åˆ†æ•°: {avg_f1:.4f}")
    
    # å¯è§†åŒ–ç»“æœ
    plt.figure(figsize=(12, 8))
    
    # AUCå¯¹æ¯”
    plt.subplot(2, 2, 1)
    folds = [r['fold'] for r in fold_results]
    aucs = [r['test_auc'] for r in fold_results]
    plt.bar(folds, aucs, color='skyblue', alpha=0.7)
    plt.axhline(y=0.7, color='red', linestyle='--', label='ç›®æ ‡AUC=0.7')
    plt.axhline(y=avg_auc, color='green', linestyle='-', label=f'å¹³å‡AUC={avg_auc:.3f}')
    plt.title('å„æŠ˜AUCç»“æœ')
    plt.xlabel('æŠ˜æ•°')
    plt.ylabel('AUC')
    plt.legend()
    plt.ylim(0.5, 1.0)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, auc in enumerate(aucs):
        plt.text(i+1, auc+0.01, f'{auc:.3f}', ha='center', va='bottom')
    
    # å‡†ç¡®ç‡å¯¹æ¯”
    plt.subplot(2, 2, 2)
    accs = [r['test_acc'] for r in fold_results]
    plt.bar(folds, accs, color='lightgreen', alpha=0.7)
    plt.axhline(y=avg_acc, color='green', linestyle='-', label=f'å¹³å‡å‡†ç¡®ç‡={avg_acc:.3f}')
    plt.title('å„æŠ˜å‡†ç¡®ç‡ç»“æœ')
    plt.xlabel('æŠ˜æ•°')
    plt.ylabel('å‡†ç¡®ç‡')
    plt.legend()
    
    # F1åˆ†æ•°å¯¹æ¯”
    plt.subplot(2, 2, 3)
    f1s = [r['test_f1'] for r in fold_results]
    plt.bar(folds, f1s, color='orange', alpha=0.7)
    plt.axhline(y=avg_f1, color='green', linestyle='-', label=f'å¹³å‡F1={avg_f1:.3f}')
    plt.title('å„æŠ˜F1åˆ†æ•°ç»“æœ')
    plt.xlabel('æŠ˜æ•°')
    plt.ylabel('F1åˆ†æ•°')
    plt.legend()
    
    # ç»¼åˆå¯¹æ¯”
    plt.subplot(2, 2, 4)
    metrics = ['AUC', 'å‡†ç¡®ç‡', 'F1åˆ†æ•°']
    values = [avg_auc, avg_acc, avg_f1]
    colors = ['skyblue', 'lightgreen', 'orange']
    bars = plt.bar(metrics, values, color=colors, alpha=0.7)
    plt.title('ä¼˜åŒ–åJoint Graphå¹³å‡æ€§èƒ½')
    plt.ylabel('åˆ†æ•°')
    plt.ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, values):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('optimized_joint_graph_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return fold_results, avg_auc

if __name__ == "__main__":
    results, final_auc = train_optimized_model()
    
    if final_auc >= 0.7:
        print(f"\nğŸ‰ æˆåŠŸï¼Joint Graphç­–ç•¥çš„AUCå·²æå‡è‡³ {final_auc:.4f}ï¼Œè¶…è¿‡äº†0.7çš„ç›®æ ‡ï¼")
    else:
        print(f"\nâš ï¸  å½“å‰AUCä¸º {final_auc:.4f}ï¼Œä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ä»¥è¾¾åˆ°0.7çš„ç›®æ ‡ã€‚")